#### MySQL

> 面经整理，主要是理论知识

##### MySQL的基本架构

<img src="C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210407221000232.png" alt="image-20210407221000232" style="zoom:67%;" />

连接器：负责跟客户端建立链接(TCP)、获取权限(用户名密码)、维持和客户度的连接

> 连接默认的超时时间为8h。可以设置长连接，但是内存消耗很大，可以使用`mysql_reset_connection`重新初始化连接资源，过程不需要重连

查询缓存：拿到一个查询请求，先查缓存，之前是否执行过。如果之前执行过，会用key-value存储在内存中，命中缓存直接返回。但是缓存命中率如果很低，不如不用。更新就会清空缓存。

> **query_cache_type**设置成为DEMAND，不使用缓存

分析器：进行词法分析，识别关键字、表名、列名等；然后进行语法分析，会判断是否有语法错误

优化器：我们有很多索引嘛，优化就是确认用哪个索引更高效；还对执行顺序进行优化，根据条件，先查哪个表，还是先关联。

执行器：执行优化器优化的操作

##### InnoDB的架构

<img src="C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210407222516528.png" alt="image-20210407222516528" style="zoom:50%;" />

分两大块·

* InnoDB In-Memory Structures
* InnoDB On-Disk Structures

**InnoDB的内存架构**

1. Buffer Pool

   正如之前提到的，MySQL 不会直接去修改磁盘的数据，因为这样做太慢了，MySQL 会先改内存，然后记录 redo log，等有空了再刷磁盘，如果内存里没有数据，就去磁盘 load。

   而这些数据存放的地方，就是 Buffer Pool。

   我们平时开发时，会用 redis 来做缓存，缓解数据库压力，其实 MySQL 自己也做了一层类似缓存的东西。

   MySQL 是以「页」（page）为单位从磁盘读取数据的，Buffer Pool 里的数据也是如此，实际上，Buffer Pool 是`a linked list of pages`，一个以页为元素的链表。

   为什么是链表？因为和缓存一样，它也需要一套淘汰算法来管理数据。

   Buffer Pool 采用基于 LRU（least recently used） 的算法来管理内存

   > 分为两个子链表，新列和旧列，旧的占3/8，新的占5/8，midpoint是两个子列表的交界；当页面被访问，会被移动到缓冲池头部；一直未被使用的会逐渐移到尾部，直至被移除

2. Change Buffer

   上面提到过，如果内存里没有对应「页」的数据，MySQL 就会去把数据从磁盘里 load 出来，如果每次需要的「页」都不同，或者不是相邻的「页」，那么每次 MySQL 都要去 load，这样就很慢了。

   于是如果 MySQL 发现你要修改的页，不在内存里，就把你要对页的修改，先记到一个叫 Change Buffer 的地方，同时记录 redo log，然后再慢慢把数据 load 到内存，load 过来后，再把 Change Buffer 里记录的修改，应用到内存（Buffer Pool）中，这个动作叫做 **merge**；而把内存数据刷到磁盘的动作，叫 **purge**：

   - **merge：Change Buffer -> Buffer Pool**
   - **purge：Buffer Pool -> Disk**

   > Change Buffer 只在操作「二级索引」（secondary index）时才使用，原因是「聚簇索引」（clustered indexes）必须是「唯一」的，也就意味着每次插入、更新，都需要检查是否已经有相同的字段存在，也就没有必要使用 Change Buffer 了；另外，「聚簇索引」操作的随机性比较小，通常在相邻的「页」进行操作，比如使用了自增主键的「聚簇索引」，那么 insert 时就是递增、有序的，不像「二级索引」，访问非常随机。

3. Adaptive Hash Index

   MySQL 索引，不管是在磁盘里，还是被 load 到内存后，都是 B+ 树，B+ 树的查找次数取决于树的深度。你看，数据都已经放到内存了，还不能“一下子”就找到它，还要“几下子”，这空间牺牲的是不是不太值得？

   尤其是那些频繁被访问的数据，每次过来都要走 B+ 树来查询，这时就会想到，我用一个指针把数据的位置记录下来不就好了？

   这就是「自适应哈希索引」（Adaptive Hash Index）。自适应，顾名思义，MySQL 会自动评估使用自适应索引是否值得，如果观察到建立哈希索引可以提升速度，则建立。

4. Log Buffer

   Log Buffer 里的 redo log，会被刷到磁盘里

**Operating System Cache**

内存与磁盘之间的一个高速缓存

**InnoDB的磁盘架构**

除了表结构定义和索引，还有一些为了高性能和高可靠而设计的角色，比如 redo log、undo log、Change Buffer，以及 Doublewrite Buffer 等等.

1. 表空间

   从架构图可以看到，Tablespaces 分为五种：

   - The System Tablespace
   - File-Per-Table Tablespaces
   - General Tablespace
   - Undo Tablespaces
   - Temporary Tablespaces

   其中，我们平时创建的表的数据，可以存放到 The System Tablespace 、File-Per-Table Tablespaces、General Tablespace 三者中的任意一个地方，具体取决于你的配置和创建表时的 sql 语句。

2. Doublewrite Buffer

   **如果说 Change Buffer 是提升性能，那么 Doublewrite Buffer 就是保证数据页的可靠性。**

   前面提到过，MySQL 以「页」为读取和写入单位，一个「页」里面有多行数据，写入数据时，MySQL 会先写内存中的页，然后再刷新到磁盘中的页。

   这时问题来了，假设在某一次从内存刷新到磁盘的过程中，一个「页」刷了一半，突然操作系统或者 MySQL 进程奔溃了，这时候，内存里的页数据被清除了，而磁盘里的页数据，刷了一半，处于一个中间状态，不尴不尬，可以说是一个「不完整」，甚至是「坏掉的」的页。

   有同学说，不是有 Redo Log 么？其实这个时候 Redo Log 也已经无力回天，Redo Log 是要在磁盘中的页数据是正常的、没有损坏的情况下，才能把磁盘里页数据 load 到内存，然后应用 Redo Log。而如果磁盘中的页数据已经损坏，是无法应用 Redo Log 的。

   所以，MySQL 在刷数据到磁盘之前，要先把数据写到另外一个地方，也就是 Doublewrite Buffer，写完后，再开始写磁盘。Doublewrite Buffer 可以理解为是一个备份（recovery），万一真的发生 crash，就可以利用 Doublewrite Buffer 来修复磁盘里的数据。

(待补全。。。

##### InnoDB和MyISAM区别，优缺点

- 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键：InnoDB 支持外键。
- 备份：InnoDB 支持在线热备份。
- 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性：MyISAM 支持压缩表和空间数据索引。



##### 一条SQL语句执行过程

查询语句：先检查该语句是否有权限，若有权限，则先查询缓存，即以这条SQL为key内存中是否有查询结果，若没有，则通过分析器进行词法分析，提取关键元素，如select，提取表名、需查询的列，判断SQL语句是否有语法错误，然后优化器根据优化算法，执行效率最好的方案。

更新语句：先查询数据，查缓存，修改更新的数据，调用引擎的API接口，写入这行数据，InnoDB把数据保存在内存中，同时记录redo log，此时redo log进入prepare状态，然后告诉执行器，执行完成了，随时可以提交。执行器收到通知后记录binlog，然后调用引擎接口，提交redo log为提交状态，更新完成

##### 事务隔离级别

Read committed、Read Uncommitted、Repeatable Read、Serializable

##### 可重复读会产生幻读吗？

会，可重复读只能解决脏读和不可重复读

##### InnoDB怎么解决幻读

**快照读**就是简单的 `select * from table where ....`

**当前读**就是 

`select * from table where ? lock in share mode` -- 共享锁 （这里可能不同版本的mysql对应命令不一样）

`select * from table where ? for update` -- 排他锁

`insert into table values(?)`

`update table set ? where ?`

`delete from table where ?`

**当前读**：在RR级别下，使用next-key locks来锁住本条记录以及索引区间

**普通(快照)读**：MVCC



**B+Tree原理**

B树是一颗平衡查找树，所有叶子在同一层

B+树是基于**B树**和**叶子节点顺序访问指针**进行实现的

B+树的两种节点：内部节点(索引节点)和叶节点，内部节点不存数据，只存索引；数据都在叶子结点内

内部节点中的key按顺序排列，对于内部节点的一个key，左子树都**小于**它，右子树都**大于等于**它，因此叶节点也是有序的，所有叶子都存有相邻节点的指针

查找类似于二叉查找树，节点内用二分

插入，寻找插入位置，判断是否需要拆分节点

B+树和红黑树相比，B+树的高度更低，磁盘IO次数更少

B+树和B树相比，由于内部节点只存索引，因此内部节点更小，如果一次性把所有同一内部节点的key存到一块磁盘，那么读取的效率变高，IO次数降低；B+树查询路径相同，都是根到叶，效率更稳定；**遍历效率高**



MySQL的索引

索引是帮助MySQL高效获取数据的**数据结构**

B+树索引

- 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。
- 因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。
- 可以指定多个列作为索引列，多个索引列共同组成键。
- 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。

哈希索引

O(1)查找，但无序

InnoDB有一个叫“自适应哈希索引”，当某个索引值被使用非常频繁，会在B+Tree索引之上再创建一个哈希索引

全文索引

用于查找文本中的关键词

空间数据索引

MyISAM支持，用于地理数据存储，会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。

##### 聚集索引和非聚集索引

聚簇索引：指主索引的叶子节点data域记录着完整的数据记录，一个表只有一个聚簇索引

1. 在表上定义主键PRIMARY KEY，InnoDB将主键索引用作聚簇索引。
2. 如果表没有定义主键，InnoDB会选择第一个不为NULL的唯一索引列用作聚簇索引。
3. 如果以上两个都没有，InnoDB 会使用一个6 字节长整型的隐式字段 ROWID字段构建聚簇索引。该ROWID字段会在插入新行时自动递增。

辅助索引的叶子结点只记录主键的值，如果用辅助索引查找，需要先找到主键，再去主索引中查找，这个过程叫回表

##### 聚集索引为啥查询快

对数据进行聚集，那么只需读取少数的数据页就能读到全部数据，减少了IO次数；与普通索引相比，减少一次回表

##### 组合索引

![image-20210408161825300](C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210408161825300.png)

##### 最左匹配原则

最左匹配原则和联合索引的索引存储结构和检索方式有关

在组合索引树中，最底层的叶子节点按照第一列a列从左到右递增排列，但是b列和c列是无序的，b列只有在a列值相等的情况下小范围内递增有序，而c列只能在a，b两列相等的情况下小范围内递增有序。

就像上面的查询，B+树会先比较a列来确定下一步应该搜索的方向，往左还是往右。如果a列相同再比较b列。但是如果查询条件没有a列，B+树就不知道第一步应该从哪个节点查起。

可以说创建的idx_abc(a,b,c)索引，相当于创建了(a)、（a,b）（a,b,c）三个索引。、

**组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(>、<、between、like)就停止匹配。**

where a = 1 and b > 10 and c = 10怎么走

a和b会用到索引

##### SQL语句命中多个索引组合时如何选择使用哪组索引

##### 索引的几大原则

1. 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

2. =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

3. **尽量选择区分度高的列作为索引**，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。

4. 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。

5. 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。



**覆盖索引**：指索引的叶节点已经包含所有需要查询的字段的值。这样就不需要回表查询主索引了，提高效率；并且只读取索引，大大减少数据访问量

##### 索引的优点

* 大大减少服务器需要扫描的数据行数

* 帮助服务器避免进行排序和分组，避免创建临时表(主要是排序和分组时创建的，有了B+Tree就不需要排序和分组了)

* 将随机IO变为顺序IO，相邻数据存在一起，提高读取效率

##### 索引的使用条件

- 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；
- 对于中到大型的表，索引就非常有效；
- 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术（应该就是垂直拆分和水平拆分？）。



##### InnoDB一棵B+树可以存放多少行数据？

约2千万或更多(增加高度为4-5层，一般为3层)...不确定



##### MySQL5.6对索引做了什么优化？

MySQL 5.6引入了索引**下推优化(ICP)**

```sql
select * from T where name like '陆%' and age = 100；
```

* 没有索引下推优化时：

对于联合索引index(name,age)，我们知道，根据B+Tree天然有序的存储特性，LIKE + 右侧模糊匹配虽可以使用到name索引，但模糊匹配后得到的结果变成无序，所以后面条件无法再使用到索引，因此需回表提取出`name like '陆%'`结果集后，只能**回表**，再通过**普通查询**得到`age = 100`的最终结果。

* 引入ICP后：

  在索引内部取到name的结果后，继续判断了age条件，由此减少了一次回表过程，提升了查询效率

  

有了索引下推优化，**可以在有like条件查询的情况下，减少回表次数**。



##### 那什么情况下会发生明明创建了索引，但是执行的时候并没有通过索引呢？

查询优化器

一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。 

优化过程大致如下：

 1、根据搜索条件，找出所有可能使用的索引 2、计算全表扫描的代价 3、计算使用不同索引执行查询的代价 4、对比各种执行方案的代价，找出成本最低的那一个



##### DDL、DML、DCL

DDL：数据定义语言，create、drop、alter，操作表、表属性

DML：数据操控语言，insert、delete、update，操作表中的记录

DCL：数据控制语言，grant、revoke，操作数据库用户



##### MySQL锁分类 和 MySQL锁机制

https://blueskykong.blog.csdn.net/article/details/112914594

1. 表锁和行锁

   表锁：对整张表加锁。开始时使用`lock`加锁，之后用到的所有表都会加锁，最后直接通过`unlock tables`释放所有的表锁

   行锁：对数据行加锁。操作过程中，使用到的所有行(索引)都会加锁。如查询二级索引会加锁，回表查聚簇索引时又会加一把锁。

2. 行锁的模式

   读写锁、读写意向锁、自增锁

   **读写锁**

   读锁，共享锁，S锁，加读锁，事务都能读取，但是不能修改，可以多个事务同时对某记录加读锁

   写锁，排他锁，X锁，独占锁，只有拥有该锁的事务能读取和修改，其他事务不行，同一时间只能有一个事务加写锁

   **读写意向锁**

   表锁和行锁虽范围不同，但是会互相冲突。**检测冲突**，如果用遍历的方式，效率很低。因此使用读写意向锁，检测冲突时，只需查看是否有意向锁即可

   意向锁是表级锁，分为读意向锁(IS锁)和写意向锁(IX锁)。事务在加读锁或写锁之前，必须先加上对应的意向锁。

   意向锁之间不会冲突，也不和自增锁冲突。它只会阻塞表级读锁或表级写锁。也不会和行锁冲突。

   **自增锁**(旧版本)

   AI锁，一种表锁，表中有自增列。插入新数据，生成自增列前，先加自增锁，阻塞其他事务的插入。

   自增锁互不兼容

   自增值一旦分配了就会+1，如果事务回滚，自增值也不会回减。所以有时候自增值会出现中断，不连续的情况

   **兼容矩阵**(第一行是已有的锁，第一列是要加的锁)

   <img src="C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210413133848734.png" alt="image-20210413133848734" style="zoom:50%;" />

   意向锁之间互不冲突

   共享锁只兼容共享锁和读意向锁兼容，和其他都冲突

   排他锁和所有锁都冲突

   自增锁只和意向锁兼容

3. 行锁的类型(算法)

   **记录锁**(Record Lock)：只锁一条记录

   **间隙锁**(Gap Lock)：加在两个索引之间的锁，或者加在第一个索引之前或最后一个索引之后的间隙。为了防止其他事务在这个范围内插入或修改记录，即保证两次读取这个范围内的数据，不会发生变化，不会出现幻读

   间隙锁之间互不冲突

   **Next-Key锁**：记录锁 + 间隙锁，一般用**左开右闭**来表示Next-Key锁。

   > 如在RR级别下，有如下Next-Key锁`(30, 49](49,50)`，之所以要锁住49和50的间隙，是为了解决幻读问题，如果不锁49和50的间隙，此时插入一条49的记录，就会产生幻读！

   **插入意向锁**：一种特殊的意向锁，表示插入的意向，只有insert时才有。和上面的表级意向锁不是一个概念嗷！

   插入意向锁之间互不冲突。只会和间隙锁、Next-Key锁冲突。

   **冲突矩阵**

   <img src="C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210413133910670.png" alt="image-20210413133910670" style="zoom:50%;" />

   - 插入意向锁不影响其他事务加其他任何锁。也就是说，一个事务已经获取了插入意向锁，对其他事务是没有任何影响的；
   - 插入意向锁与间隙锁和 Next-key 锁冲突。也就是说，一个事务想要获取插入意向锁，如果有其他事务已经加了间隙锁或 Next-key 锁，则会阻塞。

   其他类型的锁的规则较为简单：

   - 间隙锁不和其他锁（不包括插入意向锁）冲突；
   - 记录锁和记录锁冲突，Next-key 锁和 Next-key 锁冲突，记录锁和 Next-key 锁冲突；



##### 数据库悲观锁怎么实现

##### InnoDB行级锁是基于什么样的机制实现的，具体加什么锁，会不会产生死锁，什么样的场景会发生死锁

通过给索引项加锁来实现的。

##### 什么时候用行锁、什么时候用表锁

InnoDB中行锁是基于**索引**实现的，因此MySQL中行级锁不是直接锁记录，而是锁索引的。

在使用聚簇索引或唯一索引时，使用行锁；非索引使用表级锁

##### 数据库的事务？

**ACID**

原子性：事务不可分割，要么都成功，要么全部失败回滚

一致性：事务执行前后保持一致状态

隔离性：事务提交前，对其他事务不可见

持久性：一旦事务提交，则修改永久保存

> 只有满足一致性，事务的结果才是正确的
>
> 无并发，事务串行，隔离性一定满足。此时只要满足原子性，就一定能满足一致性；
>
> 有并发，必须满足原子性和隔离性，才能满足一致性
>
> 持久化是应对数据库崩溃的情况

**原子性依赖WAL**(Write ahead log)，即 redo log，先顺序写日志，后调整磁盘对象

好处：顺序写日志速度快；如果写日志过程中数据库挂了，最多日志出错，不会影响磁盘

**一致性依赖程序猿**，指数据的逻辑合理

**隔离性依赖MVCC或LBCC**，思路就是给数据库做瞬时快照，读用快照，写用锁，从而做到读写并行；LBCC就是读写锁

**持久性依赖磁盘或副本**：持久性是结果

如均分大于80分的学生中，A课程分数大于90的学生数



##### UUID作为主键对索引写的影响

##### 文件很多、用户很多，怎么分表

##### group by，having，where执行顺序

Where, Group By, Having, Order by。

##### 数据库怎么分表？水平分表和垂直分表

水平切分：同一个表的数据拆分到多个结构相同的表中，用来**缓解单个数据库的压力**

> 切分策略：哈希取模、id范围、映射表
>
> 问题：需要使用全局唯一ID、每个分片指定一个ID范围等

垂直切分：一个表按列分成对个表，可以将经常用的列和不经常用的列切分到不同的表中



##### 分库解决了什么，分表解决了什么

<img src="C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210408230437299.png" alt="image-20210408230437299" style="zoom:67%;" />

##### 分表怎么设计主键(一条数据或消息的唯一ID标识)

**原则**

1. 全局唯一性
2. 趋势递增：数据库很多是B+Tree索引，为了提高写入性能
3. 单调递增
4. 信息安全：连续的容易被扒取

123对应不同的场景；3和4是互斥的，无法同时满足

进阶的：有容灾能力、高可用、高性能、延迟低

**方法**

1. UUID：性能高，本地生成，无网络延时；16字节不易存储，信息不安全(基于mac地址生成的UUID可能不安全)，对数据库不友好(太长了，不利于建索引)

2. snowflake雪花算法

* 与指定日期的时间差(毫秒级)，41位
* 集群ID + 机器ID，10位
* 序列，12位

![image-20210408230954895](C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210408230954895.png)

优

* 毫秒数在高位，自增在低位，整体递增
* 不依赖第三方系统，以服务方式部署，稳定，性能高
* 可以根据自身业务分配bit位，灵活

缺：强依赖时钟机器，如果机器上时钟回拨，会导致发号重复或服务不可用

3. 数据库生成

   通过设置字段实现ID递增，通过读写MySQL得到ID号

   优

   * 简单，成本小
   * ID递增，灵活

   缺

   * 强依赖DB，DB挂了，服务也没了
   * ID发号性能瓶颈

4. 美团Leaf https://tech.meituan.com/2017/04/21/mt-leaf.html

   1. 对数据库方案的优化

      原方案每次获取ID都得读写一次数据库，造成数据库压力大。

      改为利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。

      各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

      主要字段：biz_tag用来区分业务，max_id表示该biz_tag目前所分配的ID号段的最大值，step表示每次分配的号段长度

      ![image-20210409093121141](C:%5CUsers%5Clqy98%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210409093121141.png)

      优

      * 很方便的线性扩展，性能高
      * ID号是趋势递增的8byte的64位数字，即使DB宕机，短时间内仍可对外服务
      * 可自定义max_id的大小，方便业务的迁移

      缺

      * ID号不够随机，安全性欠佳

      * 仍存在偶尔延时高，tp999偶尔尖刺

        双buffer优化，相当于提前取下一个号段，进缓存

      * DB宕机会造成整个系统不可用

        主从部署

      2. 对雪花算法方案的优化

         > 趋势递增ID不适用订单ID生成，这样可以计算出某公司一天的订单量，不能接收啊

         仍然采用“1 + 41 + 10 + 12”的方式组装ID。结合Zookeeper来使用。

         没看懂。。

##### MVCC

`MVCC (Multiversion Concurrency Control)` 中文全程叫**多版本并发控制**，是现代数据库（包括 `MySQL`、`Oracle`、`PostgreSQL` 等）引擎实现中常用的处理读写冲突的手段，**目的在于提高数据库高并发场景下的吞吐性能**。

如此一来，不同事务并发过程中，`SELECT` 操作可以不加锁而是通过 `MVCC` 机制读取指定的版本历史记录，并通过一些手段保证保证读取的记录值符合事务所处的隔离级别，从而解决并发场景下的读写冲突。

对数据库的任何修改的提交都不会直接覆盖之前的数据，而是产生一个新的版本与老版本共存，使得读取时可以完全不加锁。



**MVCC使得数据库读不会对数据加锁，普通的SELECT请求不会加锁，提高了数据库的并发处理能力**。借助MVCC，数据库可以实现READ COMMITTED，REPEATABLE READ等隔离级别，用户可以查看当前数据的前一个或者前几个历史版本，保证了ACID中的I特性（隔离性)。

只在`Read Committed`和`Repeatable read`两个隔离级别下工作；可以用乐观锁和悲观锁实现；

**事务快照 read view**：用来存储数据库的事务运行情况。查看所有未提交并活跃的事务，最小的XID记在xmin中，最大的记在xman中

**InnoDB的Repeatable Read级别中，会在事务执行第一个select读操作后，创建一个快照**

**InnoDB的Read Committed级别中，事务每条select都会创建一个快照**

**undo-log**：记录数据库变更操作，存储的是老版本的数据。当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。

在回滚中：undo-log分为insert undo-log和update undo-log

insert undo-log：insert时产生的log，只在事务回滚时需要，事务提交后就可以丢弃

update undo-log：delete和update产生的log，不仅事务回滚需要，一致性读也需要，所以不能随便删除

InnoDB存储引擎在每行后添加3个字段：

**事务ID**：6字节，本次修改的事务的标识符，**顺序严格递增**

**回滚指针**：7字节，写入回滚段的undo-log record，如果一行记录被更新, 则 undo log record 包含 '重建该行记录被更新之前内容' 所必须的信息。

**DB_ROW_ID**：6字节，包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。

**可见性比较算法：**

设要读取的行的最后提交事务id(即当前数据行的稳定事务id)为 `trx_id_current`
当前新开事务id为 `new_id`
当前新开事务创建的快照`read view` 中最早的事务id为`up_limit_id`, 最迟的事务id为`low_limit_id`(注意这个low_limit_id=未开启的事务id=当前最大事务id+1)
比较:

- 1.`trx_id_current < up_limit_id`, 这种情况比较好理解, 表示, 新事务在读取该行记录时, 该行记录的稳定事务ID是小于, 系统当前所有活跃的事务, 所以当前行稳定数据对新事务可见, 跳到步骤5.
- 2.`trx_id_current >= trx_id_last`, 这种情况也比较好理解, 表示, 该行记录的稳定事务id是在本次新事务创建之后才开启的, 但是却在本次新事务执行第二个select前就commit了，所以该行记录的当前值不可见, 跳到步骤4。
- 3.`trx_id_current <= trx_id_current <= trx_id_last`, 表示: 该行记录所在事务在本次新事务创建的时候处于活动状态，从up_limit_id到low_limit_id进行遍历，如果trx_id_current等于他们之中的某个事务id的话，那么不可见, 调到步骤4,否则表示可见。
- 4.从该行记录的 DB_ROLL_PTR 指针所指向的回滚段中取出最新的undo-log的版本号, 将它赋值该 `trx_id_current`，然后跳到步骤1重新开始判断。
- 5.将该可见行的值返回。



##### 一、索引优化

索引的数据结构是 B+Tree，而 B+Tree 的查询性能是比较高的，所以建立索引能提升 SQL 的查询性能。

**1、建立普通索引**

对经常出现在 where 关键字后面的表字段建立对应的索引。

**2、建立复合索引**

如果 where 关键字后面常出现的有几个字段，可以建立对应的 复合索引。要注意可以优化的一点是：将单独出现最多的字段放在前面。

例如现在我们有两个字段 a 和 b 经常会同时出现在 where 关键字后面：

```
select * from t where a = ``1` `and b = ``2``;  \* Q1 *\
```

也有很多 SQL 会单独使用字段 a 作为查询条件：

```
select * from t where a = ``2``;  \* Q2 *\
```

此时，我们可以建立复合索引 index(a,b)。因为不但 Q1 可以利用复合索引，Q2 也可以利用复合索引。

**3、最左前缀匹配原则**

如果我们使用的是复合索引，应该尽量遵循 最左前缀匹配原则。MySQL 会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配。

假如此时我们有一条 SQL ：

```
select * from t where a = ``1` `and b = ``2` `and c > ``3` `and d = ``4``;
```

那么我们应该建立的复合索引是：index(a,b,d,c) 而不是 index(a,b,c,d)。因为字段 c 是范围查询，当 MySQL 遇到范围查询就停止索引的匹配了。

大家也注意到了，其实 a,b,d 在 SQL 的位置是可以任意调整的，优化器会找到对应的复合索引。

> 还要注意一点的是：最左前缀匹配原则不但是复合索引的最左 N 个字段；也可以是单列（字符串类型）索引的最左 M 个字符。

- 例如我们常说的 like 关键字，尽量不要使用全模糊查询，因为这样用不到索引；
- 所以建议是使用右模糊查询：select * from t where name like '李%'（查询所有姓李的同学的信息）。

**4、索引下推**

很多时候，我们还可以复合索引的 索引下推 来优化 SQL 。

例如此时我们有一个复合索引：index(name,age) ，然后有一条 SQL 如下：

```
select * from user where name like ``'苏%'` `and age = ``10` `and sex = ``'m'``;
```

根据复合索引的最左前缀匹配原则，MySQL 匹配到复合索引 index(name,age) 的 name 时，就停止匹配了；然后接下来的流程就是根据主键回表，判断 age 和 sex 的条件是否同时满足，满足则返回给客户端。

但是由于有索引下推的优化，匹配到 name 时，不会立刻回表；而是先判断复合索引 index(name,age) 中的 age 是否符合条件；符合条件才进行回表接着判断 sex 是否满足，否则会被过滤掉。

那么借着 MySQL 5.6 引入的索引下推优化 ，可以做到减少回表的次数。

**5、覆盖索引**

很多时候，我们还可以 覆盖索引 来优化 SQL 。

**情况一**：SQL 只查询主键作为返回值。

主键索引（聚簇索引）的叶子节点是整行数据，而普通索引（二级索引）的叶子节点是主键的值。

所以当我们的 SQL 只查询主键值，可以直接获取对应叶子节点的内容，而避免回表。

**情况二**：SQL 的查询字段就在索引里。

复合索引：假如此时我们有一个复合索引 index(name,age) ，有一条 SQL 如下：

```
select name,age from t where name like ``'苏%'``;
```

由于是字段 name 是右模糊查询所以可以走复合索引，然后匹配到 name 时，不需要回表，因为 SQL 只是查询字段 name 和 age，所以直接返回索引值就 ok 了。

**6、普通索引**

尽量 使用普通索引 而不是唯一索引。

首先，普通索引和唯一索引的查询性能其实不会相差很多；当然了，前提是要查询的记录都在同一个数据页中，否则普通索引的性能会慢很多。

但是，普通索引的更新操作性能比唯一索引更好；其实很简单，因为普通索引能利用 change buffer 来做更新操作；而唯一索引因为要判断更新的值是否是唯一的，所以每次都需要将磁盘中的数据读取到 buffer pool 中。

**7、前缀索引**

我们要学会巧妙的使用 前缀索引，避免索引值过大。

例如有一个字段是 addr varchar(255)，但是如果一整个建立索引 [ index(addr) ]，会很浪费磁盘空间，所以会选择建立前缀索引 [ index(addr(64)) ]。

建立前缀索引，一定要关注字段的区分度。例如像身份证号码这种字段的区分度很低，只要出生地一样，前面好多个字符都是一样的；这样的话，最不理想时，可能会扫描全表。

前缀索引避免不了回表，即无法使用覆盖索引这个优化点，因为索引值只是字段的前 n 个字符，需要回表才能判断查询值是否和字段值是一致的。

**怎么解决**？

倒序存储：像身份证这种，后面的几位区分度就非常的高了；我们可以这么查询：

select field_list from t where id_card = reverse('input_id_card_string');增加 hash 字段并为 hash 字段添加索引。

**8、干净的索引列**

索引列不能参与计算，要保持索引列“干净”。

假设我们给表 student 的字段 birthday 建立了普通索引。

下面的 SQL 语句不能利用到索引来提升执行效率：

```
select * from student where DATE_FORMAT(birthday,``'%Y-%m-%d'``) = ``'2020-02-02'``;
```

我们应该改成下面这样：

```
select * from student where birthday = STR_TO_DATE(``'2020-02-02'``, ``'%Y-%m-%d'``);
```

**9、扩展索引**

我们应该尽量 扩展索引，而不是新增索引，一个表最好不要超过 5 个索引；一个表的索引越多，会导致更新操作更加耗费性能。

###### 二、SQL 优化

**1、Order By 优化**

order by 后面的字段尽量是带索引的，这样能避免使用 sort_buffer 进行排序。

- 假如有一条 SQL，根据生日查询所有学生的信息：select * from student order by birthday desc;
- 那么为了提升 SQL 的查询性能，我们可以为 birthday 字段建立索引：

```
CREATE INDEX index_birthday ON student(birthday);
```

select 后面不要带上不必要的字段，因为如果单行长度太长导致查询数据太多，MySQL 会利用 rowid 排序来代替全字段排序，这样会导致多了回表的操作。

- 如果我们只是查询学生的姓名、年龄和生日，千万不要写 select *;
- 而是只查询需要的字段：select name, age, birthday from student order by birthday desc;

**2、Join 优化**

- 在使用 join 的时候，应该让小表做驱动表。小表：总数据量最小的表
- 使用 join 语句，最好保证能利用被驱动表的索引，不然只能使用 BNL（Block Nested-Loop Join）算法，还不如不用。
- 启用 BKA（Batched Key Access） 算法，使得 NLJ 算法也能利用上 join_buffer，被驱动表可以批量查询到符合条件的值，然后可以利用 MMR（Multi-Range Read） 的顺序读盘特性来提升回表效率。
- 如果一定要用 join，而且被驱动表没有索引可以使用，那么我们可以利用临时表（create temporary table xx(...)engine=innodb;）来让 BNL 算法转为 BKA 算法，从而提升查询性能。
- join_buffer 是一个无序数组，所以每次判断都需要遍历整个 join_buffer。我们可以在业务端实现 hash join 来提升 SQL 的执行速度。

**3、Group By 优化**

- 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null。
- 尽量让 group by 过程用上表的索引，不但不需要临时表，还不需要额外的排序。
- 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表。
- 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。

**4、OR 优化**

在 Innodb 引擎下 or 关键字无法使用组合索引。

假设现在关于订单表有一条 SQL ：

```
select id，product_name from orders where mobile = ``'12345678900'` `or user_id = ``6``;
```

一般我们为了提升上面 SQL 的查询效率，会想着为字段 mobile 和 user_id 建立一个复合索引 index(mobile,user_id)；

可是我们使用 explain 可以发现执行计划里面并没有提示到使用复合索引，所以 or 关键字无法命中 mobile + user_id 的组合索引。

那么我们可以分别为两个字段建立普通索引，然后采用 union 关键字，如下所示：

```
(select id，product_name from orders where mobile = ``'12345678900'``)``union``(select id，product_name from orders where user_id = ``6``);
```

此时 mobile 和 user_id 字段都有索引，查询才最高效。

**5、IN 优化**

in 关键字适合主表大子表小，exist 关键字适合主表小子表大。由于查询优化器的不断升级，很多场景这两者性能差不多一样了，可以尝试改为 join 查询。

假设我们现在有一条 SQL ，要查询 VIP 用户的所有订单数据：

```
select id from orders where user_id in (select id from user where level = ``'VIP'``);
```

我们可以发现不会有任何关于索引的优化，所以我们可以采用 join查询，如下所示：

```
select o.id from orders o join user u on o.user_id = u.id and u.level = ``'VIP'``;
```

此时被驱动表应该是 user，那么可以利用到 user 表的主键索引，即可以使用 BKA 算法来提升 join 查询的性能。

**6、Like 优化**

like 用于模糊查询，但是如果是全模糊查询，将不能命中对应字段的索引。

假设现在关于学生表有一条 SQL：

```
SELECT name,age,birthday FROM student WHERE name like ``'%苏%'``;
```

使用 explain 可以发现执行计划提示查询未命中索引。

因为本来需求就是查询姓张的所有同学信息，所以没必要使用全模糊查询，使用右模糊查询即可。

换成下面的写法：

```
SELECT name,age,birthday FROM student WHERE name like ``'苏%'``;
```

但是产品经理一定要前后模糊匹配呢？全文索引 FULLTEXT 可以尝试一下，但是 MySQL 的全文索引不支持中文查询的。

所以说 Elasticsearch 才是终极武器！

###### 三、数据表设计优化

**1、数据类型：应该选择更简单或者占用空间更小的类型**。

- 整型选择：可以根据长度选择 tinyint、smallint、medium_int，而不是直接使用 int。
- 字符串选择：能确定字符串长度的，尽量使用 char 类型，而不是变长的 varchar 类型。
- 浮点型选择：精度要求比较高的使用 decimal 而不是 double；也可以考虑使用 BIGINT 来保存，小数位保存可以使用乘以整百来解决。
- 日期选择：尽量使用 timestamp 而不是 datetime。

**2、避免空值**：

- NULL 值依然会占用空间，并且会使索引更新更加复杂，更新 NULL 时容易发生索引分裂的现象。
- 可以使用有意义的值来代替 NULL 值，例如 “none” 字符串等等。

**3、超长字符串**：

- 一般超长字符串，varchar 难以存储，我们一般会使用 text 类型。
- 但是 text 类型的字段尽量避免放在主表中，而是抽出来在子表里，用业务主键关联。



##### 内联、左联、右联

内联：inner join

如果想把用户信息、积分、等级都列出来，那么一般会这样写：
`select * from T1 ,T3 where T1.userid = T3.userid`
其实这样的结果等同于`select * from T1 inner join T3 on T1.userid=T3.userid` 
**把两个表中都存在userid的行拼成一行(即内联)**，但后者的效率会比前者高很多，建议用后者(内联)的写法。
`select * from T1 inner join T2 on T1.userid=T2.userid`

左联：left outer join

**显示左表T1中的所有行，并把右表T2中符合条件加到左表T1中;右表T2中不符合条件，就不用加入结果表中，并且NULL表示**。

`select * from T1 left outer join T2 on T1.userid=T2.userid`

右联：right outer join

**显示右表T2中的所有行，并把左表T1中符合条件加到右表T2中;左表T1中不符合条件，就不用加入结果表中，并且NULL表示。**

`select * from T1 right outer join T2 on T1.userid=T2.userid`

全联：full outer join

显示左表T1、右表T2两边中的所有行，即把左联结果表+右联结果表组合在一起，然后过滤掉重复的。

`select * from T1 full outer join T2 on T1.userid=T2.userid`

##### 不等号会用索引吗

where a > 1 这种，如果索引只有字段a，或者a在索引的首位，可能会用索引

不等号有可能使用索引，explain查看是否使用



##### MySQL对数据去重

distinct

```sql
SELECT DISTINCT user_age
FROM user
ORDER BY user_age DESC;
```



group by

```sql
SELECT user_age
FROM user
ORDER BY user_age DESC;
```



##### 查询数据量较大怎么处理



##### redo log、undo log、binlog

redo log，负责**落盘式持久性**，只关心未来，是InnoDB存储引擎层的日志，**记录事务操作的变化，记录修改后的值，可用来恢复数据，保证数据完整性**。更新时，**先写日志，再写磁盘**。redo log日志**大小固定**，写满了就从头开始写，即**写满覆盖**

binlog，**负责副本式持久性**，只关心过去，是MySQL Service层的日志，逻辑日志，以**二进制形式记录语句的原始逻辑**，一份写到一定大小，会换下一份，**不会覆盖**

undo log：**负责原子性**，回滚日志，记录多个历史版本数据，保存事务发生前的数据的一个版本，可用于回滚，MVCC

概述

**binlog**

是啥？记录数据库表结构和表数据的变更，比如增改删创建，但不会记录查select

存啥？binlog存储每条变更的SQL语句、对应的事务id等

作用？复制和恢复数据。保证一主多从数据的一致；数据库挂了用来恢复数据

**redo log**

写啥？修改的请求在内存写完后，落磁盘之前，先写redo log，redo log记载了**这次在哪个页上做了什么修改**

> 写redo log也会有缓存，并且也需要写磁盘，不过是顺序IO，很快

作用？当修改时，写完内存但还没写到磁盘时，如果数据库挂了，可以通过redo log恢复。redo log记录的是物理变化，恢复很快

**binlog 和 redo log区别**

**存储内容**：`binlog`记录的是SQL语句(**逻辑变化**)，而redo log记录的是物理修改的内容(**物理变化**)

**功能**

`redo log`的作用是为**持久化**而生的。写完内存，如果数据库挂了，那我们可以通过`redo log`来恢复内存还没来得及刷到磁盘的数据，将`redo log`加载到内存里边，那内存就能恢复到挂掉之前的数据了。

`binlog`的作用是复制和恢复而生的。

- 主从服务器需要保持数据的一致性，通过`binlog`来同步数据。
- 如果整个数据库的数据都被删除了，`binlog`存储着所有的数据变更情况，那么可以通过`binlog`来对数据进行恢复。

又看到这里，你会想：”如果整个数据库的数据都被删除了，那我可以用`redo log`的记录来恢复吗？“**不能**

因为功能的不同，`redo log` 存储的是物理数据的变更，如果我们内存的数据已经刷到了磁盘了，那`redo log`的数据就无效了。所以`redo log`不会存储着**历史**所有数据的变更，**文件的内容会被覆盖的**。

**写入的细节**







##### InnoDB怎么保证崩溃恢复能力？

两阶段日志提交

##### 自增ID和UUID区别

自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。

插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID值。
自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
**而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。**

- 除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？

由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型（bigint）则是8个字节。
**显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。**
链接：https://www.zhihu.com/question/397289720/answer/1246287314

##### 自增ID申请完了会发生什么

自增ID达到上限用完了之后，分为两种情况：

1. 如果设置了主键，那么将会报错主键冲突。

2. 如果没有设置主键，数据库则会帮我们自动生成一个全局的row_id，新数据会**覆盖**老数据

主键尽量设置为bigint

##### explain里面有哪些字段

explain：模拟优化器执行SQL语句，在select前加上explain可以返回执行的一些信息，但不是正真执行这个SQL

字段(大概看一下)

id：id列的编号是select的序列号，有几个select就有几个id，并且id的顺序是按select出现的顺序增长的。id越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。

select type：对应行是简单还是复杂的查询

table：表示正在访问哪个表

type：这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行对应的大概范围。

possible_keys：可能会使用哪些查询来查找

keys：实际采用哪个索引对该表访问

rows：估计要读取并检测的行数，不是结果集的行数

Extra：额外信息



##### MySQL主从集群？







##### SQL语句很慢，为什么？

偶尔慢：刷新脏页(redo log写满了、内存不够了申请内存)、拿不到锁

一直很慢：没用到索引->最左前缀？索引不能表达式、函数、数据库选错了索引


